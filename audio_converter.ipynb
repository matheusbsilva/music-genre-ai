{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import time\n",
    "import glob\n",
    "import csv\n",
    "import cv2\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from numpy import array, asarray, ndarray, swapaxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms images from a directory in spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_image(filepath, savepath='./images/'):\n",
    "    \n",
    "    filepath = os.path.abspath(filepath)\n",
    "    savepath = os.path.abspath(savepath)\n",
    "    mpl.rcParams['savefig.pad_inches'] = 0\n",
    "    # Reads every audio file from filepath, returns amplitude in time(y) and sample rate(sr)\n",
    "    for folder in os.listdir(filepath):\n",
    "        folderpath = '{}/{}'.format(filepath, folder)\n",
    "        \n",
    "        for filename in os.listdir(folderpath):\n",
    "            fullpath = '{}/{}'.format(folderpath, filename)\n",
    "            print(fullpath)\n",
    "            audio_wave, sample_rate = librosa.load(fullpath)\n",
    "\n",
    "            # Applies Fourier transform in audio's amplitude\n",
    "            fourier = librosa.stft(audio_wave)\n",
    "\n",
    "            # Converts amplitude to DBs\n",
    "            \"\"\"\n",
    "            ref:scalar or callable\n",
    "                If scalar, the amplitude abs(S) is scaled relative to ref: 20 * log10(S / ref). \n",
    "                Zeros in the output correspond to positions where S == ref.\n",
    "\n",
    "                If callable, the reference value is computed as ref(S).\n",
    "            \"\"\"\n",
    "            D = librosa.amplitude_to_db(np.abs(fourier), ref=np.max)\n",
    "            \n",
    "           \n",
    "            librosa.display.specshow(D, x_axis='time', y_axis='log')\n",
    "            plt.axis('off')\n",
    "            #plt.axis('off')\n",
    "            \n",
    "            savefolder = '{}/{}'.format(savepath, folder)\n",
    "            \n",
    "            if not os.path.exists(savefolder):\n",
    "                os.makedirs(savefolder)\n",
    "            \n",
    "            plt.savefig(savefolder + '/' + filename.split('.')[0] + '-spectogram.png', bbox_inches='tight',  pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_to_image('./teste/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loads audio Data CSV\n",
    "df_tracks = pd.read_csv('fma_metadata/tracks.csv')\n",
    "df_tracks.dropna(subset = ['genre_top'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training options\n",
    "\n",
    "# Number of samples propagated through the network\n",
    "batch_size = 25\n",
    "epochs = 1\n",
    "training_size = 0.7\n",
    "\n",
    "# Image's dimensions\n",
    "img_rows, img_cols = 248, 387 \n",
    "\n",
    "\n",
    "\n",
    "# Training data size\n",
    "length = int(95*training_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set(filepath):\n",
    "    \n",
    "    x_test = []\n",
    "    x_train = []\n",
    "\n",
    "    y_test = []\n",
    "    y_train = []\n",
    "    tempY = []\n",
    "    \n",
    "    filepath = os.path.abspath(filepath)\n",
    "    \n",
    "    i = 0\n",
    "    for folder in os.listdir(filepath):\n",
    "        folderpath = '{}/{}'.format(filepath, folder)\n",
    "        \n",
    "        for filename in os.listdir(folderpath):\n",
    "            fullpath = '{}/{}'.format(folderpath, filename)\n",
    "            \n",
    "            current_track_id = filename.split('-')[0]\n",
    "            current_track_id = int(current_track_id)\n",
    "            \n",
    "            genre = df_tracks[df_tracks.track_id == current_track_id]\n",
    "            genre = genre.genre_top.to_list()[0]\n",
    "            print(i, fullpath, current_track_id, genre)\n",
    "            \n",
    "            #img = array(cv2.imread(fullpath))\n",
    "            img = cv2.imread(fullpath)\n",
    "            #img = swapaxes(img, 2,0)\n",
    "            #img = swapaxes(img, 2,1)\n",
    "\n",
    "\n",
    "            if(i < length):\n",
    "                x_train.append(img)\n",
    "                y_train.append(genre)\n",
    "            else:\n",
    "                x_test.append(img)\n",
    "                y_test.append(genre)\n",
    "        \n",
    "            i = i + 1\n",
    "\n",
    "    return x_train, y_train, x_test, y_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /home/iago/Documentos/visao_computacional/music-genre-ai/images/001/001069-spectogram.png 1069 Experimental\n",
      "1 /home/iago/Documentos/visao_computacional/music-genre-ai/images/001/001040-spectogram.png 1040 Rock\n",
      "2 /home/iago/Documentos/visao_computacional/music-genre-ai/images/001/001039-spectogram.png 1039 Rock\n",
      "3 /home/iago/Documentos/visao_computacional/music-genre-ai/images/001/001066-spectogram.png 1066 Experimental\n",
      "4 /home/iago/Documentos/visao_computacional/music-genre-ai/images/033/033049-spectogram.png 33049 Folk\n",
      "5 /home/iago/Documentos/visao_computacional/music-genre-ai/images/033/033064-spectogram.png 33064 Electronic\n",
      "6 /home/iago/Documentos/visao_computacional/music-genre-ai/images/033/033069-spectogram.png 33069 International\n",
      "7 /home/iago/Documentos/visao_computacional/music-genre-ai/images/033/033070-spectogram.png 33070 International\n",
      "8 /home/iago/Documentos/visao_computacional/music-genre-ai/images/033/033050-spectogram.png 33050 Folk\n",
      "9 /home/iago/Documentos/visao_computacional/music-genre-ai/images/033/033020-spectogram.png 33020 Rock\n",
      "10 /home/iago/Documentos/visao_computacional/music-genre-ai/images/033/033068-spectogram.png 33068 International\n",
      "11 /home/iago/Documentos/visao_computacional/music-genre-ai/images/033/033067-spectogram.png 33067 International\n",
      "12 /home/iago/Documentos/visao_computacional/music-genre-ai/images/005/005159-spectogram.png 5159 Folk\n",
      "13 /home/iago/Documentos/visao_computacional/music-genre-ai/images/005/005170-spectogram.png 5170 Folk\n",
      "14 /home/iago/Documentos/visao_computacional/music-genre-ai/images/005/005158-spectogram.png 5158 Folk\n",
      "15 /home/iago/Documentos/visao_computacional/music-genre-ai/images/005/005169-spectogram.png 5169 Folk\n",
      "16 /home/iago/Documentos/visao_computacional/music-genre-ai/images/005/005006-spectogram.png 5006 Rock\n",
      "17 /home/iago/Documentos/visao_computacional/music-genre-ai/images/005/005157-spectogram.png 5157 Folk\n",
      "18 /home/iago/Documentos/visao_computacional/music-genre-ai/images/005/005156-spectogram.png 5156 Folk\n",
      "19 /home/iago/Documentos/visao_computacional/music-genre-ai/images/005/005171-spectogram.png 5171 Folk\n",
      "20 /home/iago/Documentos/visao_computacional/music-genre-ai/images/013/013191-spectogram.png 13191 Pop\n",
      "21 /home/iago/Documentos/visao_computacional/music-genre-ai/images/013/013328-spectogram.png 13328 Pop\n",
      "22 /home/iago/Documentos/visao_computacional/music-genre-ai/images/013/013199-spectogram.png 13199 Hip-Hop\n",
      "23 /home/iago/Documentos/visao_computacional/music-genre-ai/images/013/013325-spectogram.png 13325 Rock\n",
      "24 /home/iago/Documentos/visao_computacional/music-genre-ai/images/013/013218-spectogram.png 13218 Pop\n",
      "25 /home/iago/Documentos/visao_computacional/music-genre-ai/images/013/013220-spectogram.png 13220 1\n",
      "26 /home/iago/Documentos/visao_computacional/music-genre-ai/images/013/013201-spectogram.png 13201 Hip-Hop\n",
      "27 /home/iago/Documentos/visao_computacional/music-genre-ai/images/013/013197-spectogram.png 13197 Pop\n",
      "28 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030056-spectogram.png 30056 Hip-Hop\n",
      "29 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030120-spectogram.png 30120 Experimental\n",
      "30 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030488-spectogram.png 30488 Pop\n",
      "31 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030690-spectogram.png 30690 Experimental\n",
      "32 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030702-spectogram.png 30702 Experimental\n",
      "33 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030230-spectogram.png 30230 Hip-Hop\n",
      "34 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030041-spectogram.png 30041 Hip-Hop\n",
      "35 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030487-spectogram.png 30487 Pop\n",
      "36 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030519-spectogram.png 30519 Electronic\n",
      "37 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030520-spectogram.png 30520 Electronic\n",
      "38 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030058-spectogram.png 30058 Hip-Hop\n",
      "39 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030522-spectogram.png 30522 Electronic\n",
      "40 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030486-spectogram.png 30486 Pop\n",
      "41 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030682-spectogram.png 30682 Experimental\n",
      "42 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030636-spectogram.png 30636 Experimental\n",
      "43 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030196-spectogram.png 30196 Instrumental\n",
      "44 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030059-spectogram.png 30059 Hip-Hop\n",
      "45 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030090-spectogram.png 30090 Experimental\n",
      "46 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030521-spectogram.png 30521 Electronic\n",
      "47 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030095-spectogram.png 30095 Experimental\n",
      "48 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030895-spectogram.png 30895 Electronic\n",
      "49 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030050-spectogram.png 30050 Hip-Hop\n",
      "50 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030740-spectogram.png 30740 Experimental\n",
      "51 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030043-spectogram.png 30043 Hip-Hop\n",
      "52 /home/iago/Documentos/visao_computacional/music-genre-ai/images/030/030198-spectogram.png 30198 Experimental\n",
      "53 /home/iago/Documentos/visao_computacional/music-genre-ai/images/019/019187-spectogram.png 19187 Rock\n",
      "54 /home/iago/Documentos/visao_computacional/music-genre-ai/images/019/019074-spectogram.png 19074 Pop\n",
      "55 /home/iago/Documentos/visao_computacional/music-genre-ai/images/019/019073-spectogram.png 19073 Pop\n",
      "56 /home/iago/Documentos/visao_computacional/music-genre-ai/images/019/019413-spectogram.png 19413 Pop\n",
      "57 /home/iago/Documentos/visao_computacional/music-genre-ai/images/019/019192-spectogram.png 19192 Experimental\n",
      "58 /home/iago/Documentos/visao_computacional/music-genre-ai/images/019/019412-spectogram.png 19412 Pop\n",
      "59 /home/iago/Documentos/visao_computacional/music-genre-ai/images/019/019184-spectogram.png 19184 Rock\n",
      "60 /home/iago/Documentos/visao_computacional/music-genre-ai/images/019/019179-spectogram.png 19179 Rock\n",
      "61 /home/iago/Documentos/visao_computacional/music-genre-ai/images/010/010376-spectogram.png 10376 Experimental\n",
      "62 /home/iago/Documentos/visao_computacional/music-genre-ai/images/010/010375-spectogram.png 10375 Experimental\n",
      "63 /home/iago/Documentos/visao_computacional/music-genre-ai/images/010/010377-spectogram.png 10377 Experimental\n",
      "64 /home/iago/Documentos/visao_computacional/music-genre-ai/images/010/010192-spectogram.png 10192 Hip-Hop\n",
      "65 /home/iago/Documentos/visao_computacional/music-genre-ai/images/010/010374-spectogram.png 10374 Experimental\n",
      "66 /home/iago/Documentos/visao_computacional/music-genre-ai/images/010/010381-spectogram.png 10381 Folk\n",
      "67 /home/iago/Documentos/visao_computacional/music-genre-ai/images/010/010250-spectogram.png 10250 Instrumental\n",
      "68 /home/iago/Documentos/visao_computacional/music-genre-ai/images/010/010186-spectogram.png 10186 International\n",
      "69 /home/iago/Documentos/visao_computacional/music-genre-ai/images/038/038326-spectogram.png 38326 International\n",
      "70 /home/iago/Documentos/visao_computacional/music-genre-ai/images/038/038312-spectogram.png 38312 Experimental\n",
      "71 /home/iago/Documentos/visao_computacional/music-genre-ai/images/038/038351-spectogram.png 38351 International\n",
      "72 /home/iago/Documentos/visao_computacional/music-genre-ai/images/038/038323-spectogram.png 38323 International\n",
      "73 /home/iago/Documentos/visao_computacional/music-genre-ai/images/038/038353-spectogram.png 38353 International\n",
      "74 /home/iago/Documentos/visao_computacional/music-genre-ai/images/038/038352-spectogram.png 38352 International\n",
      "75 /home/iago/Documentos/visao_computacional/music-genre-ai/images/038/038321-spectogram.png 38321 International\n",
      "76 /home/iago/Documentos/visao_computacional/music-genre-ai/images/038/038354-spectogram.png 38354 International\n",
      "77 /home/iago/Documentos/visao_computacional/music-genre-ai/images/000/000190-spectogram.png 190 Folk\n",
      "78 /home/iago/Documentos/visao_computacional/music-genre-ai/images/000/000148-spectogram.png 148 Experimental\n",
      "79 /home/iago/Documentos/visao_computacional/music-genre-ai/images/000/000010-spectogram.png 10 Pop\n",
      "80 /home/iago/Documentos/visao_computacional/music-genre-ai/images/000/000140-spectogram.png 140 Folk\n",
      "81 /home/iago/Documentos/visao_computacional/music-genre-ai/images/000/000005-spectogram.png 5 Hip-Hop\n",
      "82 /home/iago/Documentos/visao_computacional/music-genre-ai/images/000/000200-spectogram.png 200 Folk\n",
      "83 /home/iago/Documentos/visao_computacional/music-genre-ai/images/000/000182-spectogram.png 182 Rock\n",
      "84 /home/iago/Documentos/visao_computacional/music-genre-ai/images/000/000002-spectogram.png 2 Hip-Hop\n",
      "85 /home/iago/Documentos/visao_computacional/music-genre-ai/images/000/000141-spectogram.png 141 Folk\n",
      "86 /home/iago/Documentos/visao_computacional/music-genre-ai/images/037/037131-spectogram.png 37131 Electronic\n",
      "87 /home/iago/Documentos/visao_computacional/music-genre-ai/images/037/037041-spectogram.png 37041 261\n",
      "88 /home/iago/Documentos/visao_computacional/music-genre-ai/images/037/037141-spectogram.png 37141 Instrumental\n",
      "89 /home/iago/Documentos/visao_computacional/music-genre-ai/images/037/037119-spectogram.png 37119 Instrumental\n",
      "90 /home/iago/Documentos/visao_computacional/music-genre-ai/images/037/037136-spectogram.png 37136 Pop\n",
      "91 /home/iago/Documentos/visao_computacional/music-genre-ai/images/037/037113-spectogram.png 37113 Instrumental\n",
      "92 /home/iago/Documentos/visao_computacional/music-genre-ai/images/037/037111-spectogram.png 37111 Instrumental\n",
      "93 /home/iago/Documentos/visao_computacional/music-genre-ai/images/037/037121-spectogram.png 37121 Experimental\n",
      "x_train shape: (66, 248, 387, 3)\n",
      "66 train samples\n",
      "28 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = create_set('images')\n",
    "\n",
    "# Converting the data from lists to numpy arrays\n",
    "\n",
    "x_train = asarray(x_train)\n",
    "x_test = asarray(x_test)\n",
    "y_train = asarray(y_train)\n",
    "y_test = asarray(y_test)\n",
    "\n",
    "# Scaling down the RGB data\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Printing stats about the features\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_85 (Conv2D)           (None, 246, 385, 128)     3584      \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 246, 385, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 246, 385, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 244, 383, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 244, 383, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 81, 127, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 81, 127, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 80, 126, 64)       16448     \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 80, 126, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 40, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 40, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 39, 62, 64)        16448     \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 39, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 19, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 19, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 18, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 18, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 9, 15, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 9, 15, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 8, 14, 64)         16448     \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 8, 14, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 4, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 4, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 3, 6, 32)          8224      \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 3, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 3, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 16)                9232      \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_129 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 161,041\n",
      "Trainable params: 161,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 66 samples, validate on 28 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Folk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-34296d840ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#testing the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/visao_computacional/OCVVM/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Documentos/visao_computacional/OCVVM/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/visao_computacional/OCVVM/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/visao_computacional/OCVVM/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2653\u001b[0m                 array_vals.append(\n\u001b[1;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[0;32m-> 2655\u001b[0;31m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[1;32m   2656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/visao_computacional/OCVVM/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Folk'"
     ]
    }
   ],
   "source": [
    "#defining the model\n",
    "model = Sequential()\n",
    "#input\n",
    "model.add(Conv2D(128,data_format = 'channels_last', kernel_size=(3, 3),\n",
    "                 input_shape=(img_rows, img_cols,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "#convolutions\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "#output\n",
    "model.add(Dense(1))\n",
    "\n",
    "#printing model summary\n",
    "print(model.summary())\n",
    "\n",
    "#compiling the model\n",
    "model.compile(optimizer='RMSprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "#training the model\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "#testing the model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>bit_rate</th>\n",
       "      <th>comments</th>\n",
       "      <th>composer</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>duration</th>\n",
       "      <th>favorites</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>13220</td>\n",
       "      <td>small</td>\n",
       "      <td>320000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-05-19 10:57:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>Pop</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Horse On A Rock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      track_id bit_rate comments composer date_created        date_recorded  \\\n",
       "7598     13220    small   320000        0          NaN  2009-05-19 10:57:27   \n",
       "\n",
       "     duration favorites genre_top genres  ... publisher tags title  \\\n",
       "7598      NaN       192         1    Pop  ...         2  NaN    []   \n",
       "\n",
       "          Unnamed: 21 Unnamed: 22 Unnamed: 23 Unnamed: 24 Unnamed: 25  \\\n",
       "7598  Horse On A Rock         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     Unnamed: 26 Unnamed: 27  \n",
       "7598         NaN         NaN  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = int(\"13220\")\n",
    "df_tracks[df_tracks.track_id == teste]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 248, 387, 3)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
